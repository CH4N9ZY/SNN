{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from IterativeLIFModel import mem_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn_layer(in_planes, out_planes, stride, padding, kernel_size)\n",
    "cfg_cnn = [(3, 33, 1, 1, 3), (33, 33, 1, 1, 3),]\n",
    "\n",
    "# kernel size\n",
    "cfg_kernel = [32, 16, 8]\n",
    "\n",
    "# fc layer\n",
    "cfg_fc = [128, 10]\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SCNN, self).__init__()\n",
    "        in_planes_0, out_planes_0, stride_0, padding_0, kernel_size_0 = cfg_cnn[0]\n",
    "        self.conv1 = nn.Conv2d(in_planes_0, out_planes_0, kernel_size=kernel_size_0, stride=stride_0, padding=padding_0)\n",
    "        in_planes_1, out_planes_1, stride_1, padding_1, kernel_size_1 = cfg_cnn[1]\n",
    "        self.conv2 = nn.Conv2d(in_planes_1, out_planes_1, kernel_size=kernel_size_1, stride=stride_1, padding=padding_1)\n",
    "\n",
    "        self.fc1 = nn.Linear(cfg_kernel[-1] * cfg_kernel[-1] * cfg_cnn[-1][1], cfg_fc[0])\n",
    "        self.fc2 = nn.Linear(cfg_fc[0], cfg_fc[1])\n",
    "        \n",
    "    def forward(self, input, time_window=20):\n",
    "        c1_mem = c1_spike = torch.zeros(batch_size, cfg_cnn[0][1], cfg_kernel[0], cfg_kernel[0], device=device)\n",
    "        c2_mem = c2_spike = torch.zeros(batch_size, cfg_cnn[1][1], cfg_kernel[1], cfg_kernel[1], device=device)\n",
    "\n",
    "        h1_mem = h1_spike = h1_sumspike = torch.zeros(batch_size, cfg_fc[0], device=device)\n",
    "        h2_mem = h2_spike = h2_sumspike = torch.zeros(batch_size, cfg_fc[1], device=device)\n",
    "        \n",
    "        for step in range(time_window): # simulation time steps\n",
    "            x = input > torch.rand(input.size(), device=device) # prob. firing\n",
    "            c1_received = self.conv1(x.float())\n",
    "            c1_mem, c1_spike = mem_update(c1_received, c1_mem, c1_spike)\n",
    "            x = F.avg_pool2d(c1_spike, 2)\n",
    "            c2_received = self.conv2(x)\n",
    "            c2_mem, c2_spike = mem_update(c2_received, c2_mem,c2_spike)\n",
    "            x = F.avg_pool2d(c2_spike, 2)\n",
    "            x = x.view(batch_size, -1)\n",
    "            h1_received = self.fc1(x)\n",
    "            h1_mem, h1_spike = mem_update(h1_received, h1_mem, h1_spike)\n",
    "            h1_sumspike += h1_spike\n",
    "            h2_received = self.fc2(h1_spike)\n",
    "            h2_mem, h2_spike = mem_update(h2_received, h2_mem,h2_spike)\n",
    "            h2_sumspike += h2_spike\n",
    "        outputs = h2_sumspike / time_window\n",
    "        return outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
